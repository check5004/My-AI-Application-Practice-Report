# MCP への期待と考察 〜AI エージェント能力拡張の可能性〜

> 想定読了時間：6分

---

## 3-1. MCP とは何か？

- **Model Context Protocol** の略。
- AI がプラグインのように **外部モジュール**（Git, Database, Memory など）へアクセスするための統一インターフェースを提供。
- 複数の AI モデル間で **共通仕様** として機能することで、再利用性を高めることが期待される。

```mermaid
graph LR
  subgraph AI Core
    A[LLM]
  end
  A --> B[Thinking MCP]
  A --> C[Database MCP]
  A --> D[Git MCP]
  A --> E[Memory MCP]
```

---

## 3-2. MCP がもたらす拡張性

| MCP モジュール | 付与される能力 | 具体例 |
|---|---|---|
| Thinking | 段階的思考、タスク分解 | `Chain-of-Thought` を外部化し、軽量モデルでも多段思考が可能に |
| Database | 構造化データの CRUD | SQLite / Supabase などへの直接問い合わせ |
| Git | リポジトリ操作 | ブランチ作成、PR 作成、コミットメッセージ生成 |
| Memory | 永続的な会話履歴 | 長期プロジェクトでのコンテキスト保持 |

---

## 3-3. Thinking MCP のコストメリット

- 高価な "Thinking 専用 LLM" を毎回使わず、**必要なときだけ** Thinking MCP を呼び出す。
- これにより **ランニングコスト削減** ＆ **柔軟なスケーリング** が可能。

<div align="center">
  <img src="https://via.placeholder.com/600x240?text=Standard+LLM+%2B+Thinking+MCP+vs+Expensive+Thinking+LLM" alt="Thinking MCP コスト比較" height="240" />
</div>

---

## 3-4. 運用形態：クラウド vs ローカル

| 観点 | クラウドホスト | ローカル Docker |
|---|---|---|
| 導入の容易さ | ◎ | △ (イメージ作成が必要) |
| レイテンシ | △ (依存) | ◎ (localhost) |
| スリープ影響 | あり | なし |
| 機密データ | 外部送信の懸念 | 社内ネットワークで完結 |

> **所感**：API ベースでない機能（Git, ファイル I/O 等）が中心となる MCP では、**ローカルホスト運用** が特に相性が良い。

---
← 前へ [[2. Cursorエディタ活用実践]]  |  次へ → [[4. AIによるDocker利用支援]]